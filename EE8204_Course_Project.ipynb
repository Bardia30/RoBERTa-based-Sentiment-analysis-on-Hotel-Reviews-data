{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdbtFoA9xTm8"
      },
      "source": [
        "# loading the dataset\n",
        "the dataset is being loaded from the .csv file which is from https://data.world/datafiniti/hotel-reviews, and we need to retrieve the column with the name reviews.text, and make the ratings as our target with column name review.rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQtFPqKz4TYn",
        "outputId": "d18829e2-29df-4ded-9fd4-6701ef5212f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: six in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=0d677b533a336de2c0cad4900bb4a022b1b852d6834a730daf45efb5811403be\n",
            "  Stored in directory: /Users/bardiadehbasti/Library/Caches/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Requirement already satisfied: nltk in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
            "Requirement already satisfied: click in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: joblib in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from seaborn) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.25 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from seaborn) (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Collecting tensorflow\n",
            "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/0f/a5/89a9bdae9f241cad167edb6c890ef2b4c842c5ae81058a2fbfd702dba9bf/tensorflow-2.17.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading tensorflow-2.17.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow)\n",
            "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl.metadata\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/f0/af/dfbea0c69fe725e9e77259d42f4e14eb582eb094200aaf697feb36f513d8/h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/4b/49/f5e3e7e1419872b69f6f5e82ba56e33955a74bd537d8a1f5f1eff2f3668a/libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
            "  Obtaining dependency information for ml-dtypes<0.5.0,>=0.3.1 from https://files.pythonhosted.org/packages/42/6b/b2fa3e2386c2b7dde43f12b83c67f6e583039141dfbb58e5c8fd365a5a7d/ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/f3/bf/26deba06a4c910a85f78245cac7698f67cedd7efe00d04f6b3e1b3506a59/protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/11/8d/049fee0b7374b948d47a0301fb97d71af067ffd5e5d8fbe9190475a76065/grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
            "  Obtaining dependency information for tensorboard<2.18,>=2.17 from https://files.pythonhosted.org/packages/0a/32/2e8545fb0592f33e3aca5951e8b01008b76d61b440658cbdc37b4eaebf0b/tensorboard-2.17.0-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Obtaining dependency information for keras>=3.2.0 from https://files.pythonhosted.org/packages/46/43/03fa53f027e78af4a6bee3564d05cb34d9f5b924dc69c85f8ef5cb950ff1/keras-3.4.1-py3-none-any.whl.metadata\n",
            "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/5b/cc/16634e76f3647fbec18187258da3ba11184a6232dcf9073dc44579076d36/tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Collecting rich (from keras>=3.2.0->tensorflow)\n",
            "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.2.0->tensorflow)\n",
            "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.2.0->tensorflow)\n",
            "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/2b/ce/4e2356b033c4822cce66249e58c5c5f37921cdb1b05acdaa27fcb31ea5fd/optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
            "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
            "Downloading tensorflow-2.17.0-cp311-cp311-macosx_12_0_arm64.whl (236.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.2/236.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl (390 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.9/390.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl (283 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, keras, tensorflow\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.3 rich-13.7.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xbU84E2azq58",
        "outputId": "978c513a-1b48-4321-da49-d2deda2bb990"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>address</th>\n",
              "      <th>categories</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>postalCode</th>\n",
              "      <th>province</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.userCity</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>reviews.userProvince</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-09-22T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Pleasant 10 min walk along the sea front to th...</td>\n",
              "      <td>Good location away from the crouds</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Russ (kent)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-04-03T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Really lovely hotel. Stayed on the very top fl...</td>\n",
              "      <td>Great hotel with Jacuzzi bath!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A Traveler</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2014-05-13T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ett mycket bra hotell. Det som drog ner betyge...</td>\n",
              "      <td>Lugnt l��ge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Maud</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-10-27T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>Good location on the Lido.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Julie</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-03-05T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>������ ���������������</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sungchul</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  address categories      city country   latitude  longitude  \\\n",
              "0  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "1  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "2  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "3  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "4  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "\n",
              "                 name postalCode province          reviews.date  \\\n",
              "0  Hotel Russo Palace      30126       GA  2013-09-22T00:00:00Z   \n",
              "1  Hotel Russo Palace      30126       GA  2015-04-03T00:00:00Z   \n",
              "2  Hotel Russo Palace      30126       GA  2014-05-13T00:00:00Z   \n",
              "3  Hotel Russo Palace      30126       GA  2013-10-27T00:00:00Z   \n",
              "4  Hotel Russo Palace      30126       GA  2015-03-05T00:00:00Z   \n",
              "\n",
              "      reviews.dateAdded  reviews.doRecommend  reviews.id  reviews.rating  \\\n",
              "0  2016-10-24T00:00:25Z                  NaN         NaN             4.0   \n",
              "1  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "2  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "3  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "4  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  Pleasant 10 min walk along the sea front to th...   \n",
              "1  Really lovely hotel. Stayed on the very top fl...   \n",
              "2  Ett mycket bra hotell. Det som drog ner betyge...   \n",
              "3  We stayed here for four nights in October. The...   \n",
              "4  We stayed here for four nights in October. The...   \n",
              "\n",
              "                        reviews.title reviews.userCity reviews.username  \\\n",
              "0  Good location away from the crouds              NaN      Russ (kent)   \n",
              "1      Great hotel with Jacuzzi bath!              NaN       A Traveler   \n",
              "2                         Lugnt l��ge              NaN             Maud   \n",
              "3          Good location on the Lido.              NaN            Julie   \n",
              "4              ������ ���������������              NaN         sungchul   \n",
              "\n",
              "  reviews.userProvince  \n",
              "0                  NaN  \n",
              "1                  NaN  \n",
              "2                  NaN  \n",
              "3                  NaN  \n",
              "4                  NaN  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import langdetect\n",
        "from langdetect import detect, DetectorFactory\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy\n",
        "from multiprocessing import Pool\n",
        "\n",
        "#loading the dataset\n",
        "reviewsDataset = pd.read_csv('datafiniti-hotel-reviews/7282_1.csv')\n",
        "reviewsDataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug5l3yszD2gk",
        "outputId": "00be0e28-63e1-4e3e-f747-46457160c595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35888"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewsDataset['reviews.text'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdDpHPQh07xx",
        "outputId": "74eb9eb9-e60a-4cd8-ca7d-99aa98f7c600"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/bardiadehbasti/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/bardiadehbasti/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/bardiadehbasti/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#downliading the nltk library data files for tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "#initializing lemmatizer and setting English stop words set to variable stop_words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hntJUOq5Qr6"
      },
      "source": [
        "# data cleaning, tokenization\n",
        "creating a function to check whether the language is indeed english, cheking with RegEx whether the review is symbols and gibberish, and remove any review less than 4 characters.\n",
        "We also tokenize, and lemmatize the words. which is a NLP technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wstQ_1N54LSf"
      },
      "outputs": [],
      "source": [
        "#setting seed 0 for langdetect to ensure reproducibility\n",
        "langdetect.DetectorFactory.seed = 0\n",
        "\n",
        "\n",
        "#function to check whether the reviews is english or not\n",
        "def is_english(review):\n",
        "    try:\n",
        "        return detect(review) == 'en'\n",
        "    except langdetect.lang_detect_exception.LangDetectException:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "#function to clean up the reviews, with regex and applying the is_english function, also checking if the review is less than 4 characters\n",
        "def clean_review(review):\n",
        "    # Remove non-English reviews\n",
        "    if not is_english(review):\n",
        "        return None\n",
        "    # Remove symbols and gibberish\n",
        "    if re.match(r'^[^a-zA-Z0-9]+$', review):\n",
        "        return None\n",
        "    # Remove very short reviews\n",
        "    if len(review) < 4:\n",
        "        return None\n",
        "\n",
        "    # Tokenize the review\n",
        "    words = word_tokenize(review)\n",
        "    # Remove stop words and lemmatize\n",
        "    cleaned_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words and word.isalpha()]\n",
        "    \n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply cleaning function to reviews.text and keep track of valid indices\n",
        "valid_indices = []\n",
        "cleaned_reviews = []\n",
        "\n",
        "for idx, review in enumerate(reviewsDataset['reviews.text'].fillna('')):\n",
        "    cleaned_review = clean_review(review)\n",
        "    if cleaned_review:\n",
        "        valid_indices.append(idx)\n",
        "        cleaned_reviews.append(cleaned_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5IKBITrCwtc",
        "outputId": "97948203-e21d-4068-90db-7e6838715c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews: 33656\n",
            "Number of ratings: 33656\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataset to keep only valid rows\n",
        "reviewsDataset = reviewsDataset.iloc[valid_indices].copy()\n",
        "reviewsDataset['reviews.text'] = cleaned_reviews\n",
        "\n",
        "# Combine cleaned reviews.text with reviews.title\n",
        "reviewsDataset['combined_reviews'] = reviewsDataset['reviews.title'].astype(str) + \". \" + reviewsDataset['reviews.text']\n",
        "\n",
        "# Extract combined reviews and ratings\n",
        "reviews = np.array(reviewsDataset['combined_reviews'])\n",
        "ratings = np.array(reviewsDataset['reviews.rating'])\n",
        "\n",
        "# Convert ratings to binary labels (positive: rating >= 3, negative: rating < 3)\n",
        "ratings = np.array([1 if rating >= 3 else 0 for rating in ratings])\n",
        "\n",
        "# Verify the length of reviews and ratings\n",
        "print(f\"Number of reviews: {len(reviews)}\")\n",
        "print(f\"Number of ratings: {len(ratings)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JID4rZXsF0Qv"
      },
      "source": [
        "Result of cleaning: We have eliminated 2232 rows\n",
        "\n",
        "\n",
        "now we split the data to train, test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Jz1M5V5-ErSK"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, ratings, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcvH496FGdyD",
        "outputId": "508de33e-142d-4f13-e859-bdc60130d15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25242,)\n",
            "(25242,)\n",
            "(8414,)\n",
            "(8414,)\n"
          ]
        }
      ],
      "source": [
        "#checking out the shape of the train and test set\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crorx6d-HcJN"
      },
      "source": [
        "Now we prepare features, prepare training data, train Naive Bayes Classifier (it will take 3-4 minutes probably)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04rhs3q8GjM0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,Flatten, SpatialDropout1D\n",
        "\n",
        "\n",
        "# Tokenize and pad the text sequences\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_seq_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_seq_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_seq_len)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_seq_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gXSTuh9iH13W"
      },
      "outputs": [],
      "source": [
        "#now we compile the model and fit the data into the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "395/395 - 119s - 302ms/step - accuracy: 0.8599 - loss: 0.3349 - val_accuracy: 0.8842 - val_loss: 0.2832\n",
            "Epoch 2/5\n",
            "395/395 - 121s - 308ms/step - accuracy: 0.8976 - loss: 0.2518 - val_accuracy: 0.8847 - val_loss: 0.2640\n",
            "Epoch 3/5\n",
            "395/395 - 117s - 297ms/step - accuracy: 0.9115 - loss: 0.2219 - val_accuracy: 0.8853 - val_loss: 0.2668\n",
            "Epoch 4/5\n",
            "395/395 - 118s - 298ms/step - accuracy: 0.9193 - loss: 0.2010 - val_accuracy: 0.8855 - val_loss: 0.2850\n",
            "Epoch 5/5\n",
            "395/395 - 121s - 307ms/step - accuracy: 0.9276 - loss: 0.1803 - val_accuracy: 0.8823 - val_loss: 0.2868\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x5ad920950>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model (might take more than 10 minutes)\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we can evaluate the model to get the accuracy, f1-score, precision and recall. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "263/263 - 19s - 72ms/step - accuracy: 0.8823 - loss: 0.2868\n",
            "Test Accuracy: 0.88\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step\n",
            "Precision: 0.93\n",
            "Recall: 0.93\n",
            "F1-Score: 0.93\n"
          ]
        }
      ],
      "source": [
        "#evaluate the model\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "# Predict the sentiment on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Calculate precision, recall, and f1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we run a sample test to see how it will predict an unseen review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: Good location away from the crouds. pleasant min walk along sea front water bus restaurant etc hotel comfortable breakfast good quite variety room aircon work well take mosquito repelant\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Predicted Sentiment: positive\n",
            "Actual Rating Sentiment: positive\n"
          ]
        }
      ],
      "source": [
        "# Function to predict sentiment\n",
        "def predict_sentiment(review):\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_len)\n",
        "    pred = model.predict(padded)\n",
        "    return 'positive' if pred >= 0.5 else 'negative'\n",
        "\n",
        "# Test the prediction function\n",
        "sample_review = reviewsDataset['combined_reviews'].iloc[0]\n",
        "print(f\"Review: {sample_review}\")\n",
        "print(f\"Predicted Sentiment: {predict_sentiment(sample_review)}\")\n",
        "print(f\"Actual Rating Sentiment: {'positive' if ratings[0] == 1 else 'negative'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if instead of LSTM based Neural network we used a simple ANN? let's explore the second model \n",
        "\n",
        "\n",
        "# using an ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>address</th>\n",
              "      <th>categories</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>postalCode</th>\n",
              "      <th>province</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.userCity</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>reviews.userProvince</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-09-22T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Pleasant 10 min walk along the sea front to th...</td>\n",
              "      <td>Good location away from the crouds</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Russ (kent)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-04-03T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Really lovely hotel. Stayed on the very top fl...</td>\n",
              "      <td>Great hotel with Jacuzzi bath!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A Traveler</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2014-05-13T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ett mycket bra hotell. Det som drog ner betyge...</td>\n",
              "      <td>Lugnt l��ge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Maud</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-10-27T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>Good location on the Lido.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Julie</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-03-05T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>������ ���������������</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sungchul</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  address categories      city country   latitude  longitude  \\\n",
              "0  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "1  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "2  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "3  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "4  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "\n",
              "                 name postalCode province          reviews.date  \\\n",
              "0  Hotel Russo Palace      30126       GA  2013-09-22T00:00:00Z   \n",
              "1  Hotel Russo Palace      30126       GA  2015-04-03T00:00:00Z   \n",
              "2  Hotel Russo Palace      30126       GA  2014-05-13T00:00:00Z   \n",
              "3  Hotel Russo Palace      30126       GA  2013-10-27T00:00:00Z   \n",
              "4  Hotel Russo Palace      30126       GA  2015-03-05T00:00:00Z   \n",
              "\n",
              "      reviews.dateAdded  reviews.doRecommend  reviews.id  reviews.rating  \\\n",
              "0  2016-10-24T00:00:25Z                  NaN         NaN             4.0   \n",
              "1  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "2  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "3  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "4  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  Pleasant 10 min walk along the sea front to th...   \n",
              "1  Really lovely hotel. Stayed on the very top fl...   \n",
              "2  Ett mycket bra hotell. Det som drog ner betyge...   \n",
              "3  We stayed here for four nights in October. The...   \n",
              "4  We stayed here for four nights in October. The...   \n",
              "\n",
              "                        reviews.title reviews.userCity reviews.username  \\\n",
              "0  Good location away from the crouds              NaN      Russ (kent)   \n",
              "1      Great hotel with Jacuzzi bath!              NaN       A Traveler   \n",
              "2                         Lugnt l��ge              NaN             Maud   \n",
              "3          Good location on the Lido.              NaN            Julie   \n",
              "4              ������ ���������������              NaN         sungchul   \n",
              "\n",
              "  reviews.userProvince  \n",
              "0                  NaN  \n",
              "1                  NaN  \n",
              "2                  NaN  \n",
              "3                  NaN  \n",
              "4                  NaN  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading the dataset\n",
        "reviewsDataset = pd.read_csv('datafiniti-hotel-reviews/7282_1.csv')\n",
        "reviewsDataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply cleaning function to reviews.text and keep track of valid indices\n",
        "valid_indices = []\n",
        "cleaned_reviews = []\n",
        "\n",
        "for idx, review in enumerate(reviewsDataset['reviews.text'].fillna('')):\n",
        "    cleaned_review = clean_review(review)\n",
        "    if cleaned_review:\n",
        "        valid_indices.append(idx)\n",
        "        cleaned_reviews.append(cleaned_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews: 33656\n",
            "Number of ratings: 33656\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataset to keep only valid rows\n",
        "reviewsDataset = reviewsDataset.iloc[valid_indices].copy()\n",
        "reviewsDataset['reviews.text'] = cleaned_reviews\n",
        "\n",
        "# Combine cleaned reviews.text with reviews.title\n",
        "reviewsDataset['combined_reviews'] = reviewsDataset['reviews.title'].astype(str) + \". \" + reviewsDataset['reviews.text']\n",
        "\n",
        "# Extract combined reviews and ratings\n",
        "reviews = np.array(reviewsDataset['combined_reviews'])\n",
        "ratings = np.array(reviewsDataset['reviews.rating'])\n",
        "\n",
        "# Convert ratings to binary labels (positive: rating >= 3, negative: rating < 3)\n",
        "ratings = np.array([1 if rating >= 3 else 0 for rating in ratings])\n",
        "\n",
        "# Verify the length of reviews and ratings\n",
        "print(f\"Number of reviews: {len(reviews)}\")\n",
        "print(f\"Number of ratings: {len(ratings)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, ratings, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25242,)\n",
            "(25242,)\n",
            "(8414,)\n",
            "(8414,)\n"
          ]
        }
      ],
      "source": [
        "#checking out the shape of the train and test set\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize and pad the text sequences\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_seq_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_seq_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_seq_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "395/395 - 26s - 65ms/step - accuracy: 0.8325 - loss: 0.4658 - val_accuracy: 0.8804 - val_loss: 0.2781\n",
            "Epoch 2/5\n",
            "395/395 - 23s - 57ms/step - accuracy: 0.9035 - loss: 0.2332 - val_accuracy: 0.8795 - val_loss: 0.2801\n",
            "Epoch 3/5\n",
            "395/395 - 23s - 57ms/step - accuracy: 0.9519 - loss: 0.1328 - val_accuracy: 0.8708 - val_loss: 0.3453\n",
            "Epoch 4/5\n",
            "395/395 - 23s - 58ms/step - accuracy: 0.9807 - loss: 0.0631 - val_accuracy: 0.8690 - val_loss: 0.3780\n",
            "Epoch 5/5\n",
            "395/395 - 23s - 57ms/step - accuracy: 0.9883 - loss: 0.0409 - val_accuracy: 0.8633 - val_loss: 0.4275\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x5a9b8df90>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compiling the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "263/263 - 2s - 6ms/step - accuracy: 0.8633 - loss: 0.4275\n",
            "Test Accuracy: 0.86\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "Precision: 0.90\n",
            "Recall: 0.93\n",
            "F1-Score: 0.92\n"
          ]
        }
      ],
      "source": [
        "#evaluating the model with accuracy and f1-score, precision, recall\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Predict the sentiment on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "# Calculate precision, recall, and f1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: Good location away from the crouds. pleasant min walk along sea front water bus restaurant etc hotel comfortable breakfast good quite variety room aircon work well take mosquito repelant\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Predicted Sentiment: positive\n",
            "Actual Rating Sentiment: positive\n"
          ]
        }
      ],
      "source": [
        "#testing an unseen review to see how it predicts it\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(review):\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_len)\n",
        "    pred = model.predict(padded)\n",
        "    return 'positive' if pred >= 0.5 else 'negative'\n",
        "\n",
        "# Test the prediction function\n",
        "sample_review = reviewsDataset['combined_reviews'].iloc[0]\n",
        "print(f\"Review: {sample_review}\")\n",
        "print(f\"Predicted Sentiment: {predict_sentiment(sample_review)}\")\n",
        "print(f\"Actual Rating Sentiment: {'positive' if ratings[0] == 1 else 'negative'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# using RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/d0/5f/f41b14a398d484bf218d5167ec9061c1e76f500d9e25166117818c8bacda/torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: sympy in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "Successfully installed torch-2.3.1 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: rich in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/bardiadehbasti/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>address</th>\n",
              "      <th>categories</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>postalCode</th>\n",
              "      <th>province</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.userCity</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>reviews.userProvince</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-09-22T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Pleasant 10 min walk along the sea front to th...</td>\n",
              "      <td>Good location away from the crouds</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Russ (kent)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-04-03T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Really lovely hotel. Stayed on the very top fl...</td>\n",
              "      <td>Great hotel with Jacuzzi bath!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A Traveler</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2014-05-13T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ett mycket bra hotell. Det som drog ner betyge...</td>\n",
              "      <td>Lugnt l��ge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Maud</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2013-10-27T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>Good location on the Lido.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Julie</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Riviera San Nicol 11/a</td>\n",
              "      <td>Hotels</td>\n",
              "      <td>Mableton</td>\n",
              "      <td>US</td>\n",
              "      <td>45.421611</td>\n",
              "      <td>12.376187</td>\n",
              "      <td>Hotel Russo Palace</td>\n",
              "      <td>30126</td>\n",
              "      <td>GA</td>\n",
              "      <td>2015-03-05T00:00:00Z</td>\n",
              "      <td>2016-10-24T00:00:25Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>We stayed here for four nights in October. The...</td>\n",
              "      <td>������ ���������������</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sungchul</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  address categories      city country   latitude  longitude  \\\n",
              "0  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "1  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "2  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "3  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "4  Riviera San Nicol 11/a     Hotels  Mableton      US  45.421611  12.376187   \n",
              "\n",
              "                 name postalCode province          reviews.date  \\\n",
              "0  Hotel Russo Palace      30126       GA  2013-09-22T00:00:00Z   \n",
              "1  Hotel Russo Palace      30126       GA  2015-04-03T00:00:00Z   \n",
              "2  Hotel Russo Palace      30126       GA  2014-05-13T00:00:00Z   \n",
              "3  Hotel Russo Palace      30126       GA  2013-10-27T00:00:00Z   \n",
              "4  Hotel Russo Palace      30126       GA  2015-03-05T00:00:00Z   \n",
              "\n",
              "      reviews.dateAdded  reviews.doRecommend  reviews.id  reviews.rating  \\\n",
              "0  2016-10-24T00:00:25Z                  NaN         NaN             4.0   \n",
              "1  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "2  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "3  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "4  2016-10-24T00:00:25Z                  NaN         NaN             5.0   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  Pleasant 10 min walk along the sea front to th...   \n",
              "1  Really lovely hotel. Stayed on the very top fl...   \n",
              "2  Ett mycket bra hotell. Det som drog ner betyge...   \n",
              "3  We stayed here for four nights in October. The...   \n",
              "4  We stayed here for four nights in October. The...   \n",
              "\n",
              "                        reviews.title reviews.userCity reviews.username  \\\n",
              "0  Good location away from the crouds              NaN      Russ (kent)   \n",
              "1      Great hotel with Jacuzzi bath!              NaN       A Traveler   \n",
              "2                         Lugnt l��ge              NaN             Maud   \n",
              "3          Good location on the Lido.              NaN            Julie   \n",
              "4              ������ ���������������              NaN         sungchul   \n",
              "\n",
              "  reviews.userProvince  \n",
              "0                  NaN  \n",
              "1                  NaN  \n",
              "2                  NaN  \n",
              "3                  NaN  \n",
              "4                  NaN  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#redoing all the previous steps to load dataset, clean the data, with a different tokenization method, (using AutoTokenize which is from the transformers library)\n",
        "\n",
        "#loading the dataset\n",
        "reviewsDataset = pd.read_csv('datafiniti-hotel-reviews/7282_1.csv')\n",
        "reviewsDataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply cleaning function to reviews.text and keep track of valid indices\n",
        "valid_indices = []\n",
        "cleaned_reviews = []\n",
        "\n",
        "for idx, review in enumerate(reviewsDataset['reviews.text'].fillna('')):\n",
        "    cleaned_review = clean_review(review)\n",
        "    if cleaned_review:\n",
        "        valid_indices.append(idx)\n",
        "        cleaned_reviews.append(cleaned_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews: 33656\n",
            "Number of ratings: 33656\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataset to keep only valid rows\n",
        "reviewsDataset = reviewsDataset.iloc[valid_indices].copy()\n",
        "reviewsDataset['reviews.text'] = cleaned_reviews\n",
        "\n",
        "# Combine cleaned reviews.text with reviews.title\n",
        "reviewsDataset['combined_reviews'] = reviewsDataset['reviews.title'].astype(str) + \". \" + reviewsDataset['reviews.text']\n",
        "\n",
        "# Extract combined reviews and ratings\n",
        "reviews = np.array(reviewsDataset['combined_reviews'])\n",
        "ratings = np.array(reviewsDataset['reviews.rating'])\n",
        "\n",
        "# Convert ratings to binary labels (positive: rating >= 3, negative: rating < 3)\n",
        "ratings = np.array([1 if rating >= 3 else 0 for rating in ratings])\n",
        "\n",
        "# Verify the length of reviews and ratings\n",
        "print(f\"Number of reviews: {len(reviews)}\")\n",
        "print(f\"Number of ratings: {len(ratings)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reviews, ratings, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25242,)\n",
            "(25242,)\n",
            "(8414,)\n",
            "(8414,)\n"
          ]
        }
      ],
      "source": [
        "#checking out the shape of the train and test set\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we load the RoBERTa model from hugging face, and the tokenizer from AutoTokenizer. \n",
        "here is the link to the model used:\n",
        "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[85], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1070\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1070\u001b[0m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
            "\u001b[0;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
